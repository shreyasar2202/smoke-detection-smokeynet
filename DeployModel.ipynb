{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cbcb84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker import get_execution_role, Session\n",
    "\n",
    "\n",
    "\n",
    "sess = Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "model_dir = \"/home/ec2-user/SageMaker/smoke-detection-smokeynet/src\" # Replace with S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb1a94a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_mnist_model_data = sess.upload_data(\n",
    "    path=\"/home/ec2-user/SageMaker/smoke-detection-smokeynet/src/last.tar.gz\", bucket=sess.default_bucket(), key_prefix=\"model/pytorch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "433eed55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PyTorchModel(\n",
    "    entry_point=\"inference.py\",\n",
    "    source_dir=model_dir,\n",
    "    role=role,\n",
    "    model_data=pt_mnist_model_data,\n",
    "    framework_version=\"1.5.0\",\n",
    "    py_version=\"py3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73af85c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05252277",
   "metadata": {},
   "source": [
    "#### Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9002a6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "\n",
    "local_mode = False\n",
    "\n",
    "if local_mode:\n",
    "    instance_type = \"local\"\n",
    "else:\n",
    "    instance_type = \"ml.g4dn.xlarge\"\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35bce0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import boto3\n",
    "from io import BytesIO\n",
    "import pickle\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "dummy_data = np.random.rand(2, 45, 2, 3, 224, 224)\n",
    "s3_client = boto3.client(\"s3\")\n",
    "# bucket = \"smokynet-inference-images-processed\"\n",
    "# bytes_ = BytesIO()\n",
    "# np.save(bytes_, dummy_data, allow_pickle=True)\n",
    "# s3_uri = \"s3://smokynet-inference-images-processed/test/dummy_data\"\n",
    "# bytes_.seek(0)\n",
    "# parsed_s3 = urlparse(s3_uri)\n",
    "# s3.upload_fileobj(\n",
    "#         Fileobj=bytes_, Bucket=bucket, Key=parsed_s3.path[1:])\n",
    "my_array_data = BytesIO()\n",
    "pickle.dump(dummy_data, my_array_data)\n",
    "my_array_data.seek(0)\n",
    "s3_client.upload_fileobj(my_array_data, 'smokynet-inference-images-processed', 'processed_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0018005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.rand(1, 1, 2, 3, 224, 224)\n",
    "arr.size * arr.itemsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2f0c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "res = predictor.predict({'bucket_name' : 'smokynet-inference-images-processed'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97ff8024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.6568760871887207], [1.6596603393554688]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c71f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc72283a",
   "metadata": {},
   "source": [
    "#### Delete endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c484a528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not local_mode:\n",
    "    predictor.delete_endpoint()\n",
    "else:\n",
    "    os.system(\"docker container ls | grep 8080 | awk '{print $1}' | xargs docker container rm -f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ec4040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "s3_uri = \"s3://smokynet-inference-images-processed/test/dummy_data\"\n",
    "bucket_name = \"smokynet-inference-images-processed\"\n",
    "bytes_ = BytesIO()\n",
    "parsed_s3 = urlparse(s3_uri)\n",
    "s3.download_fileobj(\n",
    "    Fileobj=bytes_, Bucket=bucket_name, Key='test/dummy_data'\n",
    ")\n",
    "bytes_.seek(0)\n",
    "data = np.load(bytes_, allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d505e5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_uri = \"s3://smokynet-inference-images-processed/test/dummy_data\"\n",
    "bytes_ = BytesIO()\n",
    "parsed_s3 = urlparse(s3_uri)\n",
    "s3.download_fileobj(\n",
    "    Fileobj=bytes_, Bucket=parsed_s3.netloc, Key=parsed_s3.path[1:]\n",
    ")\n",
    "bytes_.seek(0)\n",
    "data=  np.load(bytes_, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9258c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e93209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import io\n",
    "import pickle\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "my_array = np.random.rand(2, 45, 2, 3, 224, 224)\n",
    "\n",
    "# upload without using disk\n",
    "my_array_data = io.BytesIO()\n",
    "pickle.dump(my_array, my_array_data)\n",
    "my_array_data.seek(0)\n",
    "s3_client.upload_fileobj(my_array_data, 'smokynet-inference-images-processed', 'your-file.pkl')\n",
    "\n",
    "# download without using disk\n",
    "my_array_data2 = io.BytesIO()\n",
    "s3_client.download_fileobj('smokynet-inference-images-processed', 'your-file.pkl', my_array_data2)\n",
    "my_array_data2.seek(0)\n",
    "my_array2 = pickle.load(my_array_data2)\n",
    "\n",
    "# check that everything is correct\n",
    "np.allclose(my_array, my_array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f78581",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f1573a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device='cpu'\n",
    "data = torch.tensor(my_array2, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc88605",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(my_array2, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a368ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0565b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from main_model import MainModel\n",
    "# import util_fns\n",
    "# from lightning_module import LightningModule\n",
    "import boto3\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from urllib.parse import urlparse\n",
    "import pickle\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    s3_client = boto3.client(\"s3\")\n",
    "    #assert request_content_type == \"application/json\"\n",
    "#     data = json.loads(request_body)[\"inputs\"]\n",
    "#     data = torch.tensor(data, dtype=torch.float32, device=device)\n",
    "#     s3_uri = \"s3://smokynet-inference-images-processed/test/dummy_data\"\n",
    "#     bucket_name = json.loads(request_body)[\"bucket_name\"]\n",
    "#     bytes_ = BytesIO()\n",
    "#     parsed_s3 = urlparse(s3_uri)\n",
    "#     s3.download_fileobj(\n",
    "#         Fileobj=bytes_, Bucket=bucket_name, Key=parsed_s3.path[1:]\n",
    "#     )\n",
    "#     bytes_.seek(0)\n",
    "#     data = np.load(bytes_, allow_pickle=True)\n",
    "    my_array_data2 = BytesIO()\n",
    "    s3_client.download_fileobj('smokynet-inference-images-processed', 'processed_data.pkl', my_array_data2)\n",
    "    my_array_data2.seek(0)\n",
    "    my_array2 = pickle.load(my_array_data2)\n",
    "    data = torch.tensor(my_array2, dtype=torch.float32, device=device)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2948a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn('sss','s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3ac692",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
